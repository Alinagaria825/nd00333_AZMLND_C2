# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement**
This dataset contains data about different informations (Age, Job, Marital, Loan, Contact, etc.) from different individuals.The objective is to predict whether client will subscribe into a term deposit. 
**In 1-2 sentences, explain the solution**
The best performing model is done with primary metric as AUC_weighted.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
The pipeline includes a dataset created from the provided URL using TabularDatasetFactory, then the data was split into train and test set. Hyperparameter tuning includes RandomPArameterSampling and a BanditPolicy. An SKLearn estmator was created for use with train.py.

**What are the benefits of the parameter sampler you chose?**
Random Sampling supports discrete and continuous hyperparameters. It supports early termination of low-performance runs. 

**What are the benefits of the early stopping policy you chose?**
According to Microsoft, BanditPolicy class defines an early termination policy based on slack criteria, and a frequency and delay interval for evaluation. Any run that doesn't fall within the slack factor or slack amount of the evaluation metric with respect to the best performing run will be terminated.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
In AutoML, dataset was also created rom the provided URL using TabularDatasetFactory. The model has a primary metric of AUC weighted. The hyperparameter setting includes task as classification and an experiment timeout of 30. 

## Pipeline comparison
In architecture, they are almost the same. First, they both needed a database and splitting the data into train and test sets then the optimzation metric and hyperparameter tuning. But in accuracy, higher accuracy came from automl model which has AUC weighted as primary metric.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
I think the hyperparameters must be defined better and try to use other parameter sampling and early stopping policy. This might improve the model since we will be using different type of hyperparameter tuning.
